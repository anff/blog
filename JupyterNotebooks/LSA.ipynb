{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#潜在语义模型练习\" data-toc-modified-id=\"潜在语义模型练习-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>潜在语义模型练习</a></span></li><li><span><a href=\"#潜在语义分析（LSA）\" data-toc-modified-id=\"潜在语义分析（LSA）-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>潜在语义分析（LSA）</a></span><ul class=\"toc-item\"><li><span><a href=\"#奇异值分解（SVD）\" data-toc-modified-id=\"奇异值分解（SVD）-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>奇异值分解（SVD）</a></span></li><li><span><a href=\"#非负矩阵分解\" data-toc-modified-id=\"非负矩阵分解-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>非负矩阵分解</a></span></li></ul></li><li><span><a href=\"#概率潜在语义分析\" data-toc-modified-id=\"概率潜在语义分析-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>概率潜在语义分析</a></span></li><li><span><a href=\"#潜在狄利克雷分配\" data-toc-modified-id=\"潜在狄利克雷分配-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>潜在狄利克雷分配</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gibbs抽样\" data-toc-modified-id=\"Gibbs抽样-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Gibbs抽样</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 潜在语义模型练习\n",
    "\n",
    "主要参考赵航的书"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 潜在语义分析（LSA）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的文档包含两个主题：一个是粒子物理，常用词汇为\"meson\", \"photon\"。\n",
    "另外一个是生活，常用词汇为\"girl\", \"boy\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 terms found in 12 documents.\n",
      "terms: ['the', 'photon', 'a', 'girl', 'boy', 'meson']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# documents set\n",
    "documents=[\n",
    "    \"girl boy\",\n",
    "    \"boy girl\",\n",
    "    \"girl boy\",\n",
    "    \"a boy girl\",\n",
    "    \"the boy girl\",\n",
    "    \"girl\",\n",
    "    \"boy\",\n",
    "    \n",
    "    \"the meson photon\",\n",
    "    \"a meson photon\",\n",
    "    \"photon\",\n",
    "    \"meson\",\n",
    "    \"photon meson\",\n",
    "]\n",
    "\n",
    "# setup terms set\n",
    "terms_set = set()\n",
    "for doc in documents:\n",
    "    terms = doc.split()\n",
    "    for term in terms:\n",
    "        terms_set.add(term)\n",
    "        \n",
    "print(\"%d terms found in %d documents.\"%(len(terms_set), len(documents)))\n",
    "terms_vec=[]\n",
    "terms_vec.extend(terms_set)\n",
    "print(\"terms:\", terms_vec)\n",
    "\n",
    "\n",
    "# setup terms index\n",
    "terms_index = { }\n",
    "for idx, term in enumerate(terms_set):\n",
    "    terms_index[term] = idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用频率逆文档(TFIDF)来表示term-document矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term-document (6X12) matrix setup\n",
      "[[0.    0.    0.    0.    0.597 0.    0.    0.597 0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.366 0.366 1.099 0.    0.549]\n",
      " [0.    0.    0.    0.597 0.    0.    0.    0.    0.597 0.    0.    0.   ]\n",
      " [0.347 0.347 0.347 0.231 0.231 0.693 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.347 0.347 0.347 0.231 0.231 0.    0.693 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.366 0.366 0.    1.099 0.549]]\n"
     ]
    }
   ],
   "source": [
    "# terms-documents matrix\n",
    "tf_ij=np.zeros((len(terms_set),len(documents)))\n",
    "tf_j=np.zeros(len(documents))  # number of terms in document j \n",
    "df_i=np.zeros(len(terms_set))  # number of documents which contain term i\n",
    "df=len(documents)\n",
    "\n",
    "\n",
    "term_doc_mat = np.zeros([len(terms_set), len(documents)])\n",
    "for j, doc in enumerate(documents):\n",
    "    terms = doc.split()\n",
    "    tf_j[j] = len(terms)\n",
    "    \n",
    "    add_to_df_i=np.zeros(len(terms_set))\n",
    "    for term in terms:\n",
    "        i = terms_index[term]\n",
    "        tf_ij[i][j] = tf_ij[i][j] + 1\n",
    "        add_to_df_i[i] = 1\n",
    "        \n",
    "    df_i = df_i + add_to_df_i\n",
    "\n",
    "\n",
    "# X in hang's book\n",
    "term_doc_mat = tf_ij/tf_j*np.log(df/df_i).reshape(df_i.shape[0], 1)\n",
    "        \n",
    "with np.printoptions(precision=3):\n",
    "    print(\"term-document (%dX%d) matrix setup\"%(term_doc_mat.shape[0],term_doc_mat.shape[1]))\n",
    "    print(term_doc_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 奇异值分解（SVD）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将term-documents矩阵分解为 u s vT\n",
    "保留其中主值最大的部分。\n",
    "奇异值分解的正交性要求，矩阵的部分数值为0，如何解释呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc-topic matrix\n",
      "                            topic0      topic1\n",
      "`            girl boy'   -0.020776   +0.383461\n",
      "`            boy girl'   -0.020776   +0.383461\n",
      "`            girl boy'   -0.020776   +0.383461\n",
      "`          a boy girl'   -0.081727   +0.346752\n",
      "`        the boy girl'   -0.081727   +0.346752\n",
      "`                girl'   -0.020776   +0.383461\n",
      "`                 boy'   -0.020776   +0.383461\n",
      "`    the meson photon'   -0.386577   +0.034020\n",
      "`      a meson photon'   -0.386577   +0.034020\n",
      "`              photon'   -0.478051   -0.085636\n",
      "`               meson'   -0.478051   -0.085636\n",
      "`        photon meson'   -0.478051   -0.085636\n",
      "term-topic matrix\n",
      "                            topic0      topic1\n",
      "                  the    -0.178288   +0.186259\n",
      "               photon    -0.682644   -0.095174\n",
      "                    a    -0.178288   +0.186259\n",
      "                 girl    -0.047023   +0.675462\n",
      "                  boy    -0.047023   +0.675462\n",
      "                meson    -0.682644   -0.095174\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import svd\n",
    "\n",
    "u,s,vT = svd(term_doc_mat)\n",
    "\n",
    "#print(\"term-topic matrix:\\n\", u)\n",
    "#print(\"topic-document matrix:\\n\", vT)\n",
    "#print(\"main value:\\n\", s)\n",
    "\n",
    "def print_mat(term_topic_mat, topic_document_mat):\n",
    "    print(\"doc-topic matrix\")\n",
    "    print(\" %20s   %10s  %10s\"%(\"\",\"topic0\", \"topic1\"))\n",
    "    for i, doc in enumerate(documents):\n",
    "        print(\"`%20s'  %+10f  %+10f\"%(doc, topic_document_mat[0][i], topic_document_mat[1][i]))\n",
    "\n",
    "    print(\"term-topic matrix\")\n",
    "    print(\" %20s   %10s  %10s\"%(\"\",\"topic0\", \"topic1\"))\n",
    "\n",
    "    for i, term in enumerate(terms_vec):\n",
    "        print(\" %20s   %+10f  %+10f\"%(term, term_topic_mat[i][0], term_topic_mat[i][1]))\n",
    "\n",
    "print_mat(u, vT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非负矩阵分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将term-documents矩阵$X$分解为 $WH$，其中$W$和$H$为（任意元素）非负矩阵。\n",
    "目标为优化\n",
    "$$\\sum_{ij}(WH-X)_{ij}^2$$\n",
    "优化方法采用“乘法更新规则”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 2 topics\n",
      "doc-topic matrix\n",
      "                            topic0      topic1\n",
      "`            girl boy'   +0.000000   +0.040593\n",
      "`            boy girl'   +0.000000   +0.040593\n",
      "`            girl boy'   +0.000000   +0.040593\n",
      "`          a boy girl'   +0.023796   +0.079060\n",
      "`        the boy girl'   +0.023796   +0.079060\n",
      "`                girl'   +0.000000   +0.040593\n",
      "`                 boy'   +0.000000   +0.040593\n",
      "`    the meson photon'   +0.171537   +0.257857\n",
      "`      a meson photon'   +0.171537   +0.257857\n",
      "`              photon'   +0.454545   +0.000000\n",
      "`               meson'   +0.000000   +0.636973\n",
      "`        photon meson'   +0.220744   +0.308828\n",
      "term-topic matrix\n",
      "                            topic0      topic1\n",
      "                  the    +0.244073   +0.247510\n",
      "               photon    +2.366617   +0.000086\n",
      "                    a    +0.244073   +0.247510\n",
      "                 girl    +0.000000   +0.163212\n",
      "                  boy    +0.000000   +0.163212\n",
      "                meson    +0.000673   +1.615948\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "ntopics = 2\n",
    "print(\"We want %d topics\"%ntopics)\n",
    "\n",
    "W = np.random.rand(len(terms_vec), ntopics)\n",
    "H = np.random.rand(ntopics, len(documents))\n",
    "# W * H -> X (term-document matrix)\n",
    "for i in range(100):\n",
    "    H1 = H * ((W.transpose().dot(term_doc_mat)) / (W.transpose().dot(W).dot(H)))\n",
    "    dH = H1 - H\n",
    "    H = H1\n",
    "    W1 = W*((term_doc_mat.dot(H.transpose())) / (W.dot(H.dot(H.transpose()))))\n",
    "    dW = W1 - W\n",
    "    W = W1\n",
    "    #print(np.power(dH,2).sum())\n",
    "    #print(np.power(dW,2).sum())\n",
    "    #print(np.power(term_doc_mat-W.dot(H),2).sum())\n",
    "\n",
    "print_mat(W, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概率潜在语义分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率潜在语义分析即潜在语义分析概率化版本，是一种生成模型。\n",
    "\n",
    "设文档集合为$D=\\{d_j\\}, j < |D|$，单词集合为$W=\\{w_i\\}, i < |W|$，文档$d_j$也是单词的序列，序列长度为$|d_j|$（重复单词多次计数。）\n",
    "\n",
    "概率模型给出文档$d_j$中某一单词位置（比如第一个单词），单词$w_i$出现的概率$P(w_i, d_j)$为\n",
    "$$\n",
    "P(w_i, d_j) = \n",
    "\\sum_k P(w_i, z_k) P(z_k, d_j)\n",
    "$$\n",
    "其中$P(z_k, d_j)$为文档$d_j$中某一单词选取话题$z_k$的概率，$P(w_i, z_k)$为话题$z_k$中单词$w_i$出现的概率。\n",
    "\n",
    "设文档$d_j$第$i^\\prime$个单词是单词$w_{i(d_j, i^\\prime)}$（$i^\\prime < |d_j|$），\n",
    "则文档$d_j$生成的概率为\n",
    "$$\n",
    "\\prod_{i^\\prime < |d_j|} P(w_{i(d_j, i^\\prime)}, d_j)\n",
    "=\\prod_{i < |W|} { P(w_i, d_j)^{n(w_i, d_j)} }\n",
    "$$\n",
    "$n(w_i, d_j)$为单词$i$在文档$j$中出现的频次。\n",
    "所有文档的生成概率的对数为\n",
    "$$\n",
    "L = \\sum_j \\sum_{i} n(w_i, d_j) \\log P(w_i, d_j)\n",
    "$$\n",
    "优化方法采用EM算法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 2 topics\n",
      "doc-topic matrix\n",
      "                            topic0      topic1\n",
      "`            girl boy'   +0.999998   +0.000000\n",
      "`            boy girl'   +0.999998   +0.000000\n",
      "`            girl boy'   +0.999998   +0.000000\n",
      "`          a boy girl'   +0.666665   +0.333327\n",
      "`        the boy girl'   +0.666910   +0.333082\n",
      "`                girl'   +0.999998   +0.000000\n",
      "`                 boy'   +0.999998   +0.000000\n",
      "`    the meson photon'   +0.000000   +0.999996\n",
      "`      a meson photon'   +0.000000   +0.999996\n",
      "`              photon'   +0.000000   +0.999997\n",
      "`               meson'   +0.000000   +0.999997\n",
      "`        photon meson'   +0.000000   +0.999997\n",
      "term-topic matrix\n",
      "                            topic0      topic1\n",
      "                  the    +0.000061   +0.166615\n",
      "               photon    +0.000000   +0.333355\n",
      "                    a    +0.000000   +0.166676\n",
      "                 girl    +0.499969   +0.000000\n",
      "                  boy    +0.499969   +0.000000\n",
      "                meson    +0.000000   +0.333355\n"
     ]
    }
   ],
   "source": [
    "ntopics = 2\n",
    "print(\"We want %d topics\"%ntopics)\n",
    "\n",
    "\n",
    "Pwz = np.random.rand(len(terms_vec), ntopics)\n",
    "Pzd = np.random.rand(ntopics, len(documents))\n",
    "\n",
    "nwd = np.zeros((len(terms_vec), len(documents))) # number of word `w` in document `d`\n",
    "\n",
    "# setup terms set\n",
    "for j, doc in enumerate(documents):\n",
    "    terms = doc.split()\n",
    "    for term in terms:\n",
    "        i = terms_index[term]\n",
    "        nwd[i][j] = nwd[i][j] + 1\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    \n",
    "    \n",
    "    nd = nwd.sum(axis=0)\n",
    "    \n",
    "    # add 1E-6 to avoid 0\n",
    "    # we need to inverse the elements of this matrix\n",
    "    Pwd = Pwz.dot(Pzd) + np.full((len(terms_vec),len(documents)), 1E-6)\n",
    "    \n",
    "    Pwz_new = (nwd/Pwd).dot(Pzd.transpose()) * Pwz\n",
    "    Pwz_new = Pwz_new / Pwz_new.sum(axis=0)\n",
    "    \n",
    "    \n",
    "    Pzd_new = (nwd/Pwd).transpose().dot(Pwz).transpose() * Pzd\n",
    "    Pzd_new = Pzd_new / nd\n",
    "        \n",
    "    #print(np.power(Pwz_new-Pwz,2).sum())\n",
    "    #print(np.power(Pzd_new-Pzd,2).sum())\n",
    "    #print(np.power(Pzd_new,2).sum())\n",
    "    \n",
    "    Pwz = Pwz_new\n",
    "    Pzd = Pzd_new\n",
    "\n",
    "\n",
    "print_mat(Pwz, Pzd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 潜在狄利克雷分配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设文档集合为$D=\\{d_m\\}, m<|D|$，单词集合为$W=\\{w_i\\},i < |W|$，文档$d_j$也是单词的序列，序列长度为$|d_m|$（重复单词多次计数。）。\n",
    "话题向量为$\\mathbf{z}=\\{z_m\\},m < |D|$。\n",
    "单词向量为$\\mathbf{w} = \\{w_{mn}\\}, m < |D|, n< |d_m|$。\n",
    "话题向量为$\\mathbf{z} = \\{z_{mn}\\}, m < |D|, n< |d_m|$。\n",
    "话题向量先验计数为$\\mathbf{\\alpha} = \\{\\alpha_{mk}\\}, m < |D|, k < K$。\n",
    "话题词向量先验计数为$\\mathbf{\\beta} = \\{\\beta_{ki}\\}, k < K, i < |W|$。\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mathbf{w}, \\mathbf{z}, \\mathbf{\\theta},\\mathbf{\\phi}| \\alpha, \\beta) = \n",
    "\\left[\\prod_k \\text{Dir} (\\phi_k|\\beta)\\right]\n",
    "\\left[\\prod_m \\text{Dir}(\\theta_m|\\alpha)\\right]\n",
    "\\left[\n",
    "\\prod_{mn} \\text{Cat}(z_{mn}|\\theta_m) \n",
    "\\text{Cat}(w_{mn}|\\phi_{z_{mn}})\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "我们想要求 $P(\\mathbf{z},\\theta,\\phi|\\mathbf{w})$\n",
    "$$P(\\mathbf{z},\\theta,\\phi|\\mathbf{w})\n",
    "=\n",
    "P(\\theta,\\phi|\\mathbf{z},\\mathbf{w})\n",
    "P(\\mathbf{z},\\mathbf{w})\n",
    "/P(\\mathbf{w})\n",
    "=\n",
    "P(\\theta,\\phi|\\mathbf{z},\\mathbf{w})\n",
    "P(\\mathbf{z}|\\mathbf{w})\n",
    "$$\n",
    "其中\n",
    "\n",
    "$$\n",
    "P(\\mathbf{z},\\mathbf{w}) = \\prod_{k} \\frac{B(n_k+\\beta)}{B(\\beta)} \\prod_{m} \\frac{B(n_m+\\alpha)}{B(\\alpha)}\n",
    "$$\n",
    "\n",
    "和\n",
    "\n",
    "$$\n",
    "P(\\theta,\\phi|\\mathbf{z},\\mathbf{w})\n",
    "= \\left[\\prod_m \\text{Dir}(\\theta_m|n_m+\\alpha)\\right] \\left[\\prod_k \\text{Dir}(\\phi_k|n_k+\\beta)\\right]\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs抽样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\mathbf{z}|\\mathbf{w})$可以通过Gibbs抽样方法得到。\n",
    "注意根据狄利克雷分布，\n",
    "$\\theta_m$ 的期望为 $$(n_m + \\alpha)/\\sum_k (n_{mk}+\\alpha_{mk})$$\n",
    "$\\phi_k$ 的期望为 $$(n_k + \\beta)/\\sum_{i} (n_{ki}+\\beta_{ki})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 2 topics\n",
      "doc-topic matrix\n",
      "                            topic0      topic1\n",
      "`            girl boy'   +0.325000   +0.675000\n",
      "`            boy girl'   +0.275000   +0.725000\n",
      "`            girl boy'   +0.275000   +0.725000\n",
      "`          a boy girl'   +0.220000   +0.780000\n",
      "`        the boy girl'   +0.280000   +0.720000\n",
      "`                girl'   +0.366667   +0.633333\n",
      "`                 boy'   +0.366667   +0.633333\n",
      "`    the meson photon'   +0.400000   +0.600000\n",
      "`      a meson photon'   +0.440000   +0.560000\n",
      "`              photon'   +0.533333   +0.466667\n",
      "`               meson'   +0.566667   +0.433333\n",
      "`        photon meson'   +0.575000   +0.425000\n",
      "term-topic matrix\n",
      "                            topic0      topic1\n",
      "                  the    +0.112203   +0.113434\n",
      "               photon    +0.257702   +0.112893\n",
      "                    a    +0.135446   +0.099467\n",
      "                 girl    +0.125711   +0.272875\n",
      "                  boy    +0.137431   +0.276298\n",
      "                meson    +0.231506   +0.125033\n"
     ]
    }
   ],
   "source": [
    "ntopics = 2\n",
    "print(\"We want %d topics\"%ntopics)\n",
    "\n",
    "\n",
    "alpha=0.2\n",
    "beta=0.2\n",
    "\n",
    "n_mk=np.zeros((len(documents), ntopics))\n",
    "n_kv=np.zeros((ntopics, len(terms_vec)))\n",
    "n_m=np.zeros(len(documents))\n",
    "n_k=np.zeros(ntopics)\n",
    "beta=1\n",
    "alpha=1\n",
    "\n",
    "lengths=np.zeros(len(documents),dtype=np.int)\n",
    "for m, doc in enumerate(documents):\n",
    "    lengths[m] = len(doc.split())    \n",
    "k_mn=np.zeros((len(documents), np.max(lengths)),dtype=np.int)\n",
    "    \n",
    "iters=10\n",
    "theta_mk_iters=np.zeros((iters, len(documents), ntopics))\n",
    "phi_kv_iters=np.zeros((iters, ntopics, len(terms_vec)))\n",
    "    \n",
    "\n",
    "def print_matrix():\n",
    "    print(\"doc-topic counting\")\n",
    "    print(n_mk)\n",
    "    print(\"terms counting in each doc\")\n",
    "    print(n_m)\n",
    "    print(\"document length\")\n",
    "    print(lengths)\n",
    "    print(\"topic-words counting\")\n",
    "    print(n_kv)\n",
    "    print(\"terms counting in each topic\")\n",
    "    print(n_k)\n",
    "    \n",
    "\n",
    "# intialization randomly\n",
    "# assign each word a topic\n",
    "for m, doc in enumerate(documents):\n",
    "    terms = doc.split()\n",
    "    for n, term in enumerate(terms):\n",
    "        v = terms_index[term]\n",
    "        k = int(np.random.randint(ntopics))        \n",
    "        n_mk[m, k] += 1 \n",
    "        n_m[m] += 1 \n",
    "        n_kv[k,v] += 1 \n",
    "        n_k[k] += 1\n",
    "        k_mn[m, n] = k\n",
    "        \n",
    "        \n",
    "# generate P(z|w) sample\n",
    "def Gibbs_step():\n",
    "\n",
    "    for m, doc in enumerate(documents):\n",
    "        terms = doc.split()\n",
    "        for n, term in enumerate(terms):\n",
    "            v = terms_index[term]\n",
    "\n",
    "            # current topic\n",
    "            k = k_mn[m, n]            \n",
    "            n_mk[m, k] -= 1\n",
    "            #n_m[m] -= 1\n",
    "            n_kv[k, v] -= 1\n",
    "            n_k[k] -= 1\n",
    "            \n",
    "            n_kv_ = (n_kv[:,v] + beta) / (n_kv[k,:] + beta).sum()\n",
    "            n_mk_ = (n_mk[m,:] + alpha) / (n_mk[m,:] + alpha).sum()\n",
    "            \n",
    "            #print(n_kv_)\n",
    "            #print(n_mk_)\n",
    "            \n",
    "            #print(n_kv)\n",
    "            acc = (n_kv_*n_mk_).cumsum()/(n_kv_*n_mk_).sum()\n",
    "            p = np.random.rand()\n",
    "            #print(acc)\n",
    "            kp = np.searchsorted(acc, p, side=\"left\")\n",
    "            #print(n_kv_*n_mk_,acc, p, kp)\n",
    "                        \n",
    "            k_mn[m, n] = kp\n",
    "            n_mk[m, kp] += 1\n",
    "            #n_m[m] += 1\n",
    "            n_kv[kp, v] += 1\n",
    "            n_k[kp] += 1\n",
    "\n",
    "            \n",
    "# warnming\n",
    "for _ in range(1000):\n",
    "    Gibbs_step()\n",
    "\n",
    "# average\n",
    "for it in range(iters):\n",
    "    Gibbs_step()\n",
    "    \n",
    "    theta_mk = (n_mk + alpha)/(n_mk + alpha).sum(axis=1, keepdims=True)\n",
    "    phi_kv = (n_kv + beta)/(n_kv + beta).sum(axis=1, keepdims=True)\n",
    "    #print_mat(phi_kv.transpose(), theta_mk.transpose())\n",
    "\n",
    "    theta_mk_iters[it,:,:] = theta_mk\n",
    "    phi_kv_iters[it,:,:] = phi_kv\n",
    "    \n",
    "\n",
    "\n",
    "print_mat(phi_kv_iters.mean(axis=0).transpose(), theta_mk_iters.mean(axis=0).transpose())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "24",
    "lenType": "16",
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
